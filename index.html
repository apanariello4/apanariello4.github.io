<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Aniello Panariello </title> <meta name="author" content="Aniello Panariello"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?6b8fd3aad820459e1ab9391925bd0532"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://apanariello4.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Aniello</span> Panariello </h1> <p class="desc">Ph.D. Student in Artificial Intelligence</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?23249edd73ea16aad64fe7a4243aee87" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>Tecnopolo, building MO-52</p> <p>Via Pietro Vivarelli 10</p> <p>Modena, Italy 41125</p> </div> </div> <div class="clearfix"> <p>I am Aniello Panariello, a Ph.D. student affiliated with the <a href="https://aimagelab.ing.unimore.it/" rel="external nofollow noopener" target="_blank">AImageLab</a> research group at the University of Modena and Reggio Emilia, under the guidance of <a href="https://aimagelab.ing.unimore.it/imagelab/person.asp?idpersona=38" rel="external nofollow noopener" target="_blank">Prof. Simone Calderara</a>, I am immersed in exploring Computer Vision and Deep Learning techniques. My prior experience includes leading the Computer Division for the Formula Student Team - MMR Driverless, where I focused on enhancing the perception capabilities of an autonomous racing car.</p> <p>My research journey has evolved to focus on several advanced areas in machine learning. Currently, I am deeply engaged in <strong>Continual Learning</strong>, where I develop methods that enable models to learn continuously from a stream of data without forgetting previous knowledge. I also explore <strong>Transfer Learning</strong>, aiming to leverage knowledge from one domain to improve performance in another. Additionally, my work in <strong>Compositionality</strong> involves creating models that can understand and generate complex structures from simpler components. Lastly, I am investigating <strong>Zero-Shot Models</strong>, which are designed to make accurate predictions for tasks they have never seen before. Through these endeavors, I strive to push the boundaries of what machine learning models can achieve, particularly in scenarios with limited resources.</p> <p>Previously I focused on <strong>Monocular Distance Estimation</strong>, a challenging area where I explore methods to accurately gauge distances using single-camera inputs, and <strong>Video Anomaly Detection</strong>, a field focused on identifying unusual human activities within video clips. In both domains, I employed innovative unsupervised and weakly supervised methods to maximize the utility of limited annotations while contributing to advancing these cutting-edge technologies.</p> <p>Feel free to reach me for any question or curiosity.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 2025</th> <td> I started an internship at <a href="https://www.cvc.uab.es/" rel="external nofollow noopener" target="_blank">CVC</a> in Barcelona, Spain, under the supervision of <a href="https://scholar.google.com/citations?user=Gsw2iUEAAAAJ" rel="external nofollow noopener" target="_blank">Joost van de Weijer</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 2025</th> <td> Our paper “<a href="https://arxiv.org/abs/2401.03191" rel="external nofollow noopener" target="_blank">Monocular Per-Object Distance Estimation with Masked Object Modeling</a>” has been accepted for publication in <a href="https://www.sciencedirect.com/journal/computer-vision-and-image-understanding" rel="external nofollow noopener" target="_blank">CVIU</a> (2025). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 2024</th> <td> I attended the <a href="https://bmvc2024.org/" rel="external nofollow noopener" target="_blank">BMVC2024</a> conference in Glasgow, United Kingdom. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 2024</th> <td> I have been recognized as an <a href="https://bmvc2024.org/people/reviewers/" rel="external nofollow noopener" target="_blank">outstanding reviewer</a> for the BMVC 2024 conference. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 2024</th> <td> I attended the <a href="https://eccv2024.ecva.net/" rel="external nofollow noopener" target="_blank">ECCV2024</a> conference in Milan, Italy. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 2024</th> <td> Our paper “Is Multiple Object Tracking a Matter of Specialization?“ has been accepted at <a href="https://neurips.cc/Conferences/2024" rel="external nofollow noopener" target="_blank">NeurIPS 2024</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 2024</th> <td> Our paper “CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning” has been accepted as an <em>oral</em> presentation at <a href="https://bmvc2024.org/" rel="external nofollow noopener" target="_blank">BMVC2024</a>. </td> </tr> </table> </div> <div class="text-end mt-1 mb-4" style="text-align: right;"> <a href="/news/" class="small">View All News</a> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Oct 01, 2023</th> <td> <a class="news-title" href="/blog/2023/trackflow/">TrackFlow - How Normalizing Flows can fuse multi-modal information for Multi-Object Tracking</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICCV’23</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/trackflow-480.webp 480w,/assets/img/publication_preview/trackflow-800.webp 800w,/assets/img/publication_preview/trackflow-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/trackflow.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="trackflow.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mancusi2023Trackflow" class="col-sm-8"> <div class="title">TrackFlow: Multi-Object tracking with Normalizing Flows</div> <div class="author"> Gianluca Mancusi, <em>Aniello Panariello</em>, Angelo Porrello, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Matteo Fabbri, Simone Calderara, Rita Cucchiara' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In International Conference on Computer Vision</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2308.11513" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mancusi2023Trackflow/mancusi2023Trackflow.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/mancusi2023trackflow/poster_trackflow_iccv2023.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>The multi-object tracking field has recently seen a renewed interest in the good old schema of *tracking-by-detection*, as its simplicity and strong priors spare it from the complex design and painful babysitting of *tracking-by-attention* approaches. In view of this, we aim at extending tracking-by-detection to **multi-modal** settings, where a comprehensive cost has to be computed from heterogeneous information *e.g.* 2D motion cues, visual appearance, and pose estimates. More precisely, we follow a case study where a rough estimate of 3D information is also available and must be merged with other traditional metrics (*e.g.*, the IoU). To achieve that, recent approaches resort to either simple rules or complex heuristics to balance the contribution of each cost. However, *i)* they require careful tuning of tailored hyperparameters on a hold-out set, and *ii)* they imply these costs to be independent, which does not hold in reality. We address these issues by building upon an elegant probabilistic formulation, which considers the cost of a candidate association as the *negative log-likelihood* yielded by a deep density estimator trained to model the conditional joint probability distribution of correct associations. Our experiments, conducted on both simulated and real benchmarks, show that our approach consistently enhances the performance of several tracking-by-detection algorithms.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mancusi2023Trackflow</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TrackFlow: Multi-Object tracking with Normalizing Flows}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mancusi, Gianluca and Panariello, Aniello and Porrello, Angelo and Fabbri, Matteo and Calderara, Simone and Cucchiara, Rita}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVIU’25</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DistFormer-480.webp 480w,/assets/img/publication_preview/DistFormer-800.webp 800w,/assets/img/publication_preview/DistFormer-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/DistFormer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DistFormer.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="panariello2025Monocular" class="col-sm-8"> <div class="title">Monocular Per-Object Distance Estimation with Masked Object Modeling</div> <div class="author"> <em>Aniello Panariello</em>, Gianluca Mancusi, Fedy Haj Ali, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Angelo Porrello, Simone Calderara, Rita Cucchiara' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Computer Vision and Image Understanding</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2401.03191" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/panariello2025Monocular/panariello2025Monocular.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/apanariello4/DistFormer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Per-object distance estimation is critical in surveillance and autonomous driving, where safety is crucial. While existing methods rely on geometric or deep supervised features, only a few attempts have been made to leverage self-supervised learning. In this respect, our paper draws inspiration from Masked Image Modeling (MiM) and extends it to multi-object tasks. While MiM focuses on extracting global image-level representations, it struggles with individual objects within the image. This is detrimental for distance estimation, as objects far away correspond to negligible portions of the image. Conversely, our strategy, termed Masked Object Modeling (MoM), enables a novel application of masking techniques. In a few words, we devise an auxiliary objective that reconstructs the portions of the image pertaining to the objects detected in the scene. The training phase is performed in a single unified stage, simultaneously optimizing the masking objective and the downstream loss (i.e., distance estimation). We evaluate the effectiveness of MoM on a novel reference architecture (DistFormer) on the standard KITTI, NuScenes, and MOTSynth datasets. Our evaluation reveals that our framework surpasses the SoTA and highlights its robust regularization properties. The MoM strategy enhances both zero-shot and few-shot capabilities, from synthetic to real domain. Finally, it furthers the robustness of the model in the presence of occluded or poorly detected objects.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">panariello2025Monocular</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Monocular Per-Object Distance Estimation with Masked Object Modeling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Panariello, Aniello and Mancusi, Gianluca and Haj Ali, Fedy and Porrello, Angelo and Calderara, Simone and Cucchiara, Rita}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Vision and Image Understanding}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">BMVC’24</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cgil-480.webp 480w,/assets/img/publication_preview/cgil-800.webp 800w,/assets/img/publication_preview/cgil-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/cgil.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cgil.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="frascaroli2024CLIP" class="col-sm-8"> <div class="title">CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning</div> <div class="author"> Emanuele Frascaroli, <em>Aniello Panariello</em>, Pietro Buzzega, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Lorenzo Bonicelli, Angelo Porrello, Simone Calderara' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In British Machine Vision Conference</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Oral Presentation</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2407.15793" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/frascaroli2024CLIP/frascaroli2024CLIP.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/aimagelab/mammoth" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> <div class="abstract hidden"> <p>With the emergence of Transformers and Vision-Language Models (VLMs) such as CLIP, large pre-trained models have become a common strategy to enhance performance in Continual Learning scenarios. This led to the development of numerous prompting strategies to effectively fine-tune transformer-based models without succumbing to catastrophic forgetting. However, these methods struggle to specialize the model on domains significantly deviating from the pre-training and preserving its zero-shot capabilities. In this work, we propose **Continual Generative training for Incremental prompt-Learning**, a novel approach to mitigate forgetting while adapting a VLM, which exploits generative replay to align prompts to tasks. We also introduce a new metric to evaluate zero-shot capabilities within CL benchmarks. Through extensive experiments on different domains, we demonstrate the effectiveness of our framework in adapting to new tasks while improving zero-shot capabilities. Further analysis reveals that our approach can bridge the gap with joint prompt tuning. The codebase is available at https://github.com/aimagelab/mammoth.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">frascaroli2024CLIP</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Frascaroli, Emanuele and Panariello, Aniello and Buzzega, Pietro and Bonicelli, Lorenzo and Porrello, Angelo and Calderara, Simone}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{British Machine Vision Conference}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS’24</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/pasta-480.webp 480w,/assets/img/publication_preview/pasta-800.webp 800w,/assets/img/publication_preview/pasta-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/pasta.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pasta.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mancusi2024is" class="col-sm-8"> <div class="title">Is Multiple Object Tracking a Matter of Specialization?</div> <div class="author"> Gianluca Mancusi, Mattia Bernardi, <em>Aniello Panariello</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Angelo Porrello, Simone Calderara, Rita Cucchiara' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2411.00553" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mancusi2024is/mancusi2024is.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://aimagelab.github.io/PASTA/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>End-to-end transformer-based trackers have achieved remarkable performance on most human-related datasets. However, training these trackers in heterogeneous scenarios poses significant challenges, including negative interference - where the model learns conflicting scene-specific parameters - and limited domain gener- alization, which often necessitates expensive fine-tuning to adapt the models to new domains. In response to these challenges, we introduce Parameter-efficient Scenario-specific Tracking A rchitecture (PASTA), a novel framework that com- bines Parameter-Efficient Fine-Tuning (PEFT) and Modular Deep Learning (MDL). Specifically, we define key scenario attributes (e.g., camera-viewpoint, lighting condition) and train specialized PEFT modules for each attribute. These expert modules are combined in parameter space, enabling systematic generalization to new domains without increasing inference time. Extensive experiments on MOT- Synth, along with zero-shot evaluations on MOT17 and PersonPath22 demonstrate that a neural tracker built from carefully selected modules surpasses its monolithic counterpart.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mancusi2024is</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mancusi, Gianluca and Bernardi, Mattia and Panariello, Aniello and Porrello, Angelo and Calderara, Simone and Cucchiara, Rita}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Is Multiple Object Tracking a Matter of Specialization?}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61.%70%61%6E%61%72%69%65%6C%6C%6F%34@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/apanariello4" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/apanariello" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=YnVl5pQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">Feel free to contact me!</div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Aniello Panariello. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>